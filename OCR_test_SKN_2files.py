# -*- coding: utf-8 -*-
"""OCR_test_combine file_SKN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18nr8ApsCWKbEVQSRcfl92u_NR8J1Aule

# 1. install package
"""

!pip install pymupdf pytesseract pdf2image pillow
!apt-get install -y tesseract-ocr
!apt-get install -y tesseract-ocr-tha tesseract-ocr-eng

"""# 2. import library"""

import os
import base64
from io import BytesIO
import fitz  # PyMuPDF
from PIL import Image
import pytesseract
import re
import json
from pdf2image import convert_from_bytes


from google.colab import drive
drive.mount('/content/drive')

"""# 3. OCR from Base64"""

'''def ocr_pdf_from_base64(base64_str, dpi=300, ocr_language='tha+eng'):
    content_bytes = base64.b64decode(base64_str)
    pdf_stream = BytesIO(content_bytes)
    doc = fitz.open(stream=pdf_stream, filetype="pdf")

    full_text = ""
    print(f"Total pages: {len(doc)}")

    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text = page.get_text("text")

        if len(text.strip()) > 100:
            print(f"Page {page_num+1}: Text-based ‚Üí Extracting")
            full_text += f"\n\n--- Page {page_num+1} (Text) ---\n{text}"
        else:
            print(f"Page {page_num+1}: Image-based ‚Üí Running OCR")
            pix = page.get_pixmap(dpi=dpi)
            img = Image.open(BytesIO(pix.tobytes("png")))
            ocr_text = pytesseract.image_to_string(img, lang=ocr_language)
            full_text += f"\n\n--- Page {page_num+1} (OCR) ---\n{ocr_text}"

    return full_text
'''
def ocr_pdf_from_base64_pages(base64_str, dpi=300, lang='tha+eng'):
    content_bytes = base64.b64decode(base64_str)
    doc = fitz.open(stream=BytesIO(content_bytes), filetype="pdf")
    page_texts = []

    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text = page.get_text().strip()

        if len(text) > 100:
            print(f"Page {page_num+1}: Text-based")
        else:
            print(f"Page {page_num+1}: Image-based ‚Üí OCR")
            pix = page.get_pixmap(dpi=dpi)
            img = Image.open(BytesIO(pix.tobytes("png")))
            text = pytesseract.image_to_string(img, lang=lang)

        page_texts.append(text)

    return page_texts

"""# 4. clear OCR"""

def clean_ocr_text(raw_text):
    cleaned_lines = []
    for line in raw_text.splitlines():
        line = line.strip()
        if not line or re.match(r"^-{3,}$", line):
            continue
        cleaned_lines.append(line)
    return "\n".join(cleaned_lines)

"""# 5. clean text"""

def clean_text(text):
    text = re.sub(r'(\d)\s+(\d)', r'\1\2', text)
    text = re.sub(r'([A-Z])\s+(\d)', r'\1\2', text)
    text = re.sub(r'(\d)\s+([A-Z])', r'\1\2', text)
    return text.strip()

"""# 6. Extract from OCR"""

def extract_fields_from_text(text):
    result = {}

    study_match = re.search(r"Study\s*:\s*(.+)", text, re.IGNORECASE)
    visit_match = re.search(r"Visit\s*:\s*(.+)", text, re.IGNORECASE)
    pid_match = re.search(r"P(?:ID|IO|LD|OD)\s*:\s*(\d+)", text, re.IGNORECASE)
    fixed_id_match = re.search(r"F[^\n:]*?(?:ID|lD|Id|iD)[^\n]*?:\s*([0-9\-]+)", text, re.IGNORECASE)
    initials_match = re.search(r"Initials\s*:\s*([A-Z]+)", text, re.IGNORECASE)

    result["Study"] = clean_text(study_match.group(1)) if study_match else None
    result["Visit"] = clean_text(visit_match.group(1)) if visit_match else None
    result["PID"] = int(pid_match.group(1)) if pid_match else None
    result["Fixed ID"] = fixed_id_match.group(1).strip() if fixed_id_match else None
    result["Initials"] = initials_match.group(1).strip() if initials_match else None

    return result

folder_path = "/content/drive/MyDrive/OCR_test"
results_per_file = {}

for filename in os.listdir(folder_path):
    if not filename.lower().endswith(".pdf"):
        continue

    print(f"\nProcessing {filename}...")

    pdf_path = os.path.join(folder_path, filename)
    with open(pdf_path, "rb") as f:
        base64_str = base64.b64encode(f.read()).decode("utf-8")

    page_texts = ocr_pdf_from_base64_pages(base64_str)
    file_results = []

    for i, raw_text in enumerate(page_texts):
        cleaned = clean_ocr_text(raw_text)
        fields = extract_fields_from_text(cleaned)
        file_results.append(fields)

        # optional: export raw text for debug
        with open(f"{filename}_page{i+1}.txt", "w", encoding="utf-8") as f:
            f.write(cleaned)

    results_per_file[filename] = file_results

    # export JSON ‡∏ï‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
    json_file = filename.replace(".pdf", ".json")
    with open(json_file, "w", encoding="utf-8") as f:
        json.dump(file_results, f, ensure_ascii=False, indent=4)

# Show all output as JSON
print(json.dumps(results_per_file, ensure_ascii=False, indent=4))

folder_path = "/content/drive/MyDrive/OCR_test"
output_folder = "/content/drive/MyDrive/OCR_output"
os.makedirs(output_folder, exist_ok=True)

results_per_file = {}

for filename in os.listdir(folder_path):
    if not filename.lower().endswith(".pdf"):
        continue

    print(f"\nProcessing {filename}...")

    pdf_path = os.path.join(folder_path, filename)
    with open(pdf_path, "rb") as f:
        base64_str = base64.b64encode(f.read()).decode("utf-8")

    page_texts = ocr_pdf_from_base64_pages(base64_str)
    file_results = []

    for i, raw_text in enumerate(page_texts):
        cleaned = clean_ocr_text(raw_text)
        fields = extract_fields_from_text(cleaned)
        file_results.append(fields)

    results_per_file[filename] = file_results

    # üìÇ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏¢‡πà‡∏≠‡∏¢‡∏ï‡∏≤‡∏°‡∏ä‡∏∑‡πà‡∏≠ PDF (‡∏ï‡∏±‡∏î .pdf ‡∏≠‡∏≠‡∏Å)
    subfolder_name = os.path.splitext(filename)[0]
    subfolder_path = os.path.join(output_folder, subfolder_name)
    os.makedirs(subfolder_path, exist_ok=True)

    # üíæ export JSON ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏¢‡πà‡∏≠‡∏¢
    output_json_path = os.path.join(subfolder_path, f"{subfolder_name}.json")
    with open(output_json_path, "w", encoding="utf-8") as f:
        json.dump(file_results, f, ensure_ascii=False, indent=4)

# Show all output as JSON
print(json.dumps(results_per_file, ensure_ascii=False, indent=4))

"""# 7. test

# 8. ‡∏´‡∏•‡∏≤‡∏¢‡πÜ file ‡πÉ‡∏ô folder ‡∏ó‡∏µ‡πà‡∏°‡∏µ

#9. export json
"""